"""
DSPy Optimizer Functions
========================
COPRO, MIPROv2 ë“± DSPy ìµœì í™” í•¨ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.

ğŸ”¥ ë‘ ê°€ì§€ ìµœì í™” ë°©ë²•:
1ï¸âƒ£ COPRO (Collaborative Prompt Optimization)
   - Signatureì˜ ì„¤ëª…ë¬¸(instruction)ì„ ìë™ ê°œì„ 
   - ìš©ë„: ì„¤ëª…ë¬¸ë§Œ ìµœì í™”í•˜ê³ ì í•  ë•Œ

2ï¸âƒ£ MIPROv2 (Mixed Instruction and PRompt Optimization v2)
   - ë² ì´ì§€ì•ˆ ìµœì í™”ë¡œ ì„¤ëª…ë¬¸ + Few-shot ì˜ˆì œ ëª¨ë‘ ìµœì í™”
   - ìš©ë„: Zero-shotìœ¼ë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì˜ˆì œê°€ 200ê°œ ì´ìƒì¸ ê²½ìš°

ğŸ†• Early Stopping & Step Logging:
   - ê° ìµœì í™” ë‹¨ê³„ë§ˆë‹¤ ì„±ëŠ¥ ë¡œê¹…
   - ì„±ëŠ¥ì´ í–¥ìƒë˜ì§€ ì•Šìœ¼ë©´ early stopping
   - ê°€ì¥ ì¢‹ì€ í”„ë¡¬í”„íŠ¸ ìë™ ë³´ì¡´
"""

import time
import copy
import json
import os
import dspy
from datetime import datetime
from dataclasses import dataclass, field
from typing import List, Tuple, Optional, Callable, Dict, Any
from .metric import normalized_metric, MAX_SCORE
from .evaluation import evaluate_with_dspy
from .logger import PerformanceTracker
from .config import OptimizerConfig, RESULTS_DIR


# ============================================
# Optimization State & Logging
# ============================================

@dataclass
class OptimizationStep:
    """ë‹¨ì¼ ìµœì í™” ë‹¨ê³„ ì •ë³´"""
    step: int
    score: float
    normalized_score: float
    instruction: str
    num_demos: int
    timestamp: str
    is_best: bool = False
    improvement: float = 0.0


@dataclass
class OptimizationState:
    """ìµœì í™” ìƒíƒœ ê´€ë¦¬"""
    best_score: float = 0.0
    best_module: Optional[dspy.Module] = None
    best_step: int = 0
    steps_without_improvement: int = 0
    history: List[OptimizationStep] = field(default_factory=list)
    start_time: float = field(default_factory=time.time)
    # ìë™ ì €ì¥ ì„¤ì •
    save_dir: str = field(default_factory=lambda: RESULTS_DIR)
    experiment_name: str = "optimization"
    auto_save: bool = True
    
    def update(self, step: int, score: float, module: dspy.Module, instruction: str = "", num_demos: int = 0) -> bool:
        """
        ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ê°œì„  ì—¬ë¶€ ë°˜í™˜
        
        Returns:
            True if improved, False otherwise
        """
        normalized = score / MAX_SCORE if score > 1 else score
        improvement = score - self.best_score
        # ì²« ë²ˆì§¸ ì—…ë°ì´íŠ¸ì´ê±°ë‚˜ ì ìˆ˜ê°€ ê°œì„ ë˜ë©´ bestë¡œ ì„¤ì •
        is_best = (self.best_module is None) or (score > self.best_score)
        
        step_info = OptimizationStep(
            step=step,
            score=score,
            normalized_score=normalized,
            instruction=instruction[:200] + "..." if len(instruction) > 200 else instruction,
            num_demos=num_demos,
            timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            is_best=is_best,
            improvement=improvement
        )
        self.history.append(step_info)
        
        if is_best:
            self.best_score = score
            self.best_module = copy.deepcopy(module)
            self.best_step = step
            self.steps_without_improvement = 0
            
            # Best ëª¨ë¸ ìë™ ì €ì¥
            if self.auto_save and self.best_module is not None:
                self._save_best_module(step)
            
            return True
        else:
            self.steps_without_improvement += 1
            return False
    
    def _save_best_module(self, step: int):
        """Best ëª¨ë¸ ì €ì¥"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"best_model_step{step}_{timestamp}.json"
            save_path = os.path.join(self.save_dir, filename)
            
            self.best_module.save(save_path)
            print(f"   ğŸ’¾ Best ëª¨ë¸ ì €ì¥: {filename} (score: {self.best_score:.3f})")
        except Exception as e:
            print(f"   âš ï¸ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def should_stop(self, patience: int) -> bool:
        """Early stopping ì¡°ê±´ í™•ì¸"""
        return self.steps_without_improvement >= patience
    
    def get_elapsed_time(self) -> float:
        """ê²½ê³¼ ì‹œê°„ (ì´ˆ)"""
        return time.time() - self.start_time
    
    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "best_score": self.best_score,
            "best_step": self.best_step,
            "total_steps": len(self.history),
            "elapsed_time": self.get_elapsed_time(),
            "history": [
                {
                    "step": s.step,
                    "score": s.score,
                    "normalized_score": s.normalized_score,
                    "instruction": s.instruction,
                    "num_demos": s.num_demos,
                    "timestamp": s.timestamp,
                    "is_best": s.is_best,
                    "improvement": s.improvement
                }
                for s in self.history
            ]
        }
    
    def save(self, path: str = None):
        """ìƒíƒœë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
        if path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            path = os.path.join(RESULTS_DIR, f"optimization_state_{timestamp}.json")
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ìµœì í™” ìƒíƒœ ì €ì¥: {path}")
        return path


class OptimizationLogger:
    """ìµœì í™” ê³¼ì • ë¡œê±°"""
    
    def __init__(self, experiment_name: str = "optimization"):
        self.experiment_name = experiment_name
        self.logs: List[Dict] = []
        self.previous_instruction: str = ""  # ì´ì „ instruction ì €ì¥
        self.original_instruction: str = ""  # ìµœì´ˆ instruction ì €ì¥
    
    def set_original_instruction(self, instruction: str):
        """ì›ë³¸ instruction ì €ì¥ (ìµœì í™” ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
        self.original_instruction = instruction
        self.previous_instruction = instruction
        print(f"\n{'ğŸ“'*25}")
        print("ğŸ“‹ ì›ë³¸ Instruction:")
        print(f"{'ğŸ“'*25}")
        print(f"{instruction}")
        print(f"{'ğŸ“'*25}\n")
    
    def log_instruction_change(self, step: int, new_instruction: str):
        """Instruction ë³€ê²½ í™•ì¸ ë° ë¡œê¹…"""
        changed = new_instruction != self.previous_instruction
        
        print(f"\n{'ğŸ”'*25}")
        print(f"ğŸ“ Step {step} Instruction ë³€ê²½ í™•ì¸")
        print(f"{'ğŸ”'*25}")
        
        if changed:
            print(f"âœ… Instruction ë³€ê²½ë¨!")
            print(f"\n[ì´ì „]")
            print(f"{self.previous_instruction[:300]}{'...' if len(self.previous_instruction) > 300 else ''}")
            print(f"\n[í˜„ì¬]")
            print(f"{new_instruction[:300]}{'...' if len(new_instruction) > 300 else ''}")
            
            # ì›ë³¸ê³¼ ë¹„êµ
            if new_instruction != self.original_instruction:
                print(f"\nğŸ“Š ì›ë³¸ ëŒ€ë¹„ ë³€ê²½: âœ… ì˜ˆ")
            else:
                print(f"\nğŸ“Š ì›ë³¸ ëŒ€ë¹„ ë³€ê²½: âŒ ì•„ë‹ˆì˜¤ (ì›ë³¸ìœ¼ë¡œ ë³µê·€)")
        else:
            print(f"âŒ Instruction ë³€ê²½ ì—†ìŒ (ì´ì „ê³¼ ë™ì¼)")
        
        print(f"{'ğŸ”'*25}\n")
        
        self.previous_instruction = new_instruction
        return changed
    
    def log_final_instruction_comparison(self, final_instruction: str):
        """ìµœì¢… instructionê³¼ ì›ë³¸ ë¹„êµ"""
        print(f"\n{'ğŸ¯'*25}")
        print("ğŸ“‹ Instruction ìµœì¢… ë¹„êµ")
        print(f"{'ğŸ¯'*25}")
        
        if final_instruction != self.original_instruction:
            print(f"âœ… Instructionì´ ìµœì í™”ë¨!")
            print(f"\n[ì›ë³¸]")
            print(f"{self.original_instruction}")
            print(f"\n[ìµœì í™”ë¨]")
            print(f"{final_instruction}")
        else:
            print(f"âš ï¸ Instructionì´ ë³€ê²½ë˜ì§€ ì•ŠìŒ (ì›ë³¸ê³¼ ë™ì¼)")
            print(f"\n[Instruction]")
            print(f"{final_instruction}")
        
        print(f"{'ğŸ¯'*25}\n")
    
    def log_step(self, step: int, score: float, is_best: bool, details: Dict = None):
        """ë‹¨ê³„ë³„ ë¡œê¹…"""
        log_entry = {
            "step": step,
            "score": score,
            "is_best": is_best,
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            **(details or {})
        }
        self.logs.append(log_entry)
        
        # ì½˜ì†” ì¶œë ¥
        best_marker = "â­ BEST" if is_best else ""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š Step {step} ê²°ê³¼ {best_marker}")
        print(f"{'='*60}")
        print(f"   ì ìˆ˜: {score:.4f}")
        
        if details:
            if details.get('num_demos'):
                print(f"   Demos: {details['num_demos']}ê°œ")
            if details.get('improvement'):
                print(f"   ê°œì„ : {details['improvement']:+.4f}")
    
    def log_early_stop(self, step: int, patience: int, best_step: int):
        """Early stopping ë¡œê¹…"""
        print(f"\n{'ğŸ›‘'*20}")
        print(f"âš ï¸  Early Stopping at Step {step}")
        print(f"   {patience}íšŒ ì—°ì† ê°œì„  ì—†ìŒ")
        print(f"   Best Step: {best_step}")
        print(f"{'ğŸ›‘'*20}")
    
    def log_final(self, state: OptimizationState):
        """ìµœì¢… ê²°ê³¼ ë¡œê¹…"""
        elapsed = state.get_elapsed_time()
        
        print(f"\n{'ğŸ¯'*20}")
        print(f"âœ… ìµœì í™” ì™„ë£Œ")
        print(f"{'ğŸ¯'*20}")
        print(f"   ì´ ë‹¨ê³„: {len(state.history)}")
        print(f"   Best Step: {state.best_step}")
        print(f"   Best Score: {state.best_score:.4f}")
        print(f"   ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ ({elapsed/60:.1f}ë¶„)")
        
        # ë‹¨ê³„ë³„ ì ìˆ˜ ë³€í™” ì‹œê°í™”
        print(f"\nğŸ“ˆ ì ìˆ˜ ë³€í™”:")
        for s in state.history:
            bar = "â–ˆ" * int(s.score * 10)
            best_mark = " â­" if s.is_best else ""
            print(f"   Step {s.step}: {bar} {s.score:.3f}{best_mark}")


# ============================================
# Optimizer with Early Stopping
# ============================================

def optimize_with_copro_and_logging(
    module: dspy.Module,
    train_examples: List[dspy.Example],
    test_examples: List[dspy.Example],
    metric_fn: Callable = None,
    breadth: int = 10,
    depth: int = 3,
    init_temperature: float = 0.9,
    num_threads: int = 16,
    patience: int = 2,
    min_improvement: float = 0.01,
    tracker: 'PerformanceTracker' = None
) -> Tuple[dspy.Module, OptimizationState]:
    """
    COPRO ìµœì í™” + ë‹¨ê³„ë³„ ë¡œê¹… + Early Stopping
    
    Args:
        module: ìµœì í™”í•  DSPy ëª¨ë“ˆ
        train_examples: í•™ìŠµ ë°ì´í„°
        test_examples: í…ŒìŠ¤íŠ¸ ë°ì´í„° (ê° ë‹¨ê³„ í‰ê°€ìš©)
        metric_fn: ë©”íŠ¸ë¦­ í•¨ìˆ˜
        breadth: ê° ë‹¨ê³„ì—ì„œ ìƒì„±í•  í›„ë³´ ìˆ˜
        depth: ìµœëŒ€ ìµœì í™” ë°˜ë³µ íšŸìˆ˜
        init_temperature: ì´ˆê¸° temperature
        num_threads: ë³‘ë ¬ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜
        patience: early stopping patience (ì—°ì† NíšŒ ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨)
        min_improvement: ìµœì†Œ ê°œì„  ì„ê³„ê°’
        tracker: PerformanceTracker (ê·¸ë˜í”„/CSV ì €ì¥ìš©)
    
    Returns:
        (best_module, optimization_state)
    """
    try:
        from dspy.teleprompt import COPRO
        
        if metric_fn is None:
            metric_fn = normalized_metric
        
        state = OptimizationState(
            experiment_name="copro",
            auto_save=True
        )
        logger = OptimizationLogger("copro")
        
        # breadth ìµœì†Œê°’ ê²€ì¦
        if breadth < 2:
            print(f"âš ï¸ breadth={breadth}ëŠ” ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. ìµœì†Œê°’ 2ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            breadth = 2
        
        print("ğŸš€ COPRO ìµœì í™” ì‹œì‘ (Early Stopping í™œì„±í™”)")
        print("   ğŸ“ ìµœì í™” ëŒ€ìƒ: Signature ì„¤ëª…ë¬¸ (Instruction)")
        print(f"   ğŸ”§ ì„¤ì •: breadth={breadth}, depth={depth}, patience={patience}")
        print("="*60)
        
        # ì›ë³¸ instruction ì €ì¥ ë° ì¶œë ¥
        original_instruction = _get_instruction(module)
        logger.set_original_instruction(original_instruction)
        
        # ì´ˆê¸° í‰ê°€ (ë² ì´ìŠ¤ë¼ì¸)
        print("\nğŸ“Š Depth 0: ë² ì´ìŠ¤ë¼ì¸ í‰ê°€")
        baseline_results = evaluate_with_dspy(module, test_examples, None, "Baseline (Test)", num_threads=num_threads)
        baseline_score = baseline_results['avg_score']
        
        # Baselineì—ëŠ” Train ì ìˆ˜ ì—†ìŒ (ì•„ì§ ìµœì í™” ì „)
        baseline_results['train_score'] = 0
        baseline_results['train_normalized'] = 0
        
        # Trackerì— ìˆ˜ë™ ë¡œê¹…
        if tracker:
            tracker.log_step(baseline_results, "Baseline (Test)")
        
        instruction = _get_instruction(module)
        state.update(0, baseline_score, module, instruction, 0)
        logger.log_step(0, baseline_score, True, {"instruction": instruction})
        
        # ê·¸ë˜í”„ ì €ì¥
        if tracker:
            tracker.plot_metrics()
        
        current_module = copy.deepcopy(module)
        
        # ë‹¨ê³„ë³„ ìµœì í™” (Depth)
        for step in range(1, depth + 1):
            print(f"\n{'ğŸ”„'*20}")
            print(f"Depth {step}/{depth}: COPRO ìµœì í™” ì¤‘...")
            print(f"{'ğŸ”„'*20}")
            
            step_start = time.time()
            
            # COPRO 1ë‹¨ê³„ ì‹¤í–‰ (track_stats=Trueë¡œ ì ìˆ˜ ìº¡ì²˜)
            optimizer = COPRO(
                metric=metric_fn,
                breadth=breadth,
                depth=1,  # í•œ ë‹¨ê³„ì”©ë§Œ
                init_temperature=init_temperature,
                verbose=True,
                track_stats=True  # ì ìˆ˜ ì¶”ì  í™œì„±í™”!
            )
            
            try:
                optimized_module = optimizer.compile(
                    current_module,
                    trainset=train_examples,
                    eval_kwargs=dict(num_threads=num_threads, display_progress=True)
                )
            except Exception as e:
                print(f"âš ï¸ Step {step} ìµœì í™” ì‹¤íŒ¨: {e}")
                continue
            
            step_time = time.time() - step_start
            
            # Train ì ìˆ˜: COPROê°€ ìº¡ì²˜í•œ results_bestì—ì„œ ì¶”ì¶œ
            train_score = 0.0
            train_score_normalized = 0.0
            
            if hasattr(optimized_module, 'results_best'):
                # results_best: {predictor_id: {"max": [...], "average": [...], ...}}
                for pred_id, stats in optimized_module.results_best.items():
                    if stats.get('max') and len(stats['max']) > 0:
                        # ë§ˆì§€ë§‰ depthì˜ ìµœê³  ì ìˆ˜ ì‚¬ìš©
                        raw_score = stats['max'][-1]
                        
                        # ì ìˆ˜ ì •ê·œí™”: ë‹¤ì–‘í•œ í˜•ì‹ ì²˜ë¦¬
                        # - 0~1: ì´ë¯¸ ì •ê·œí™”ë¨
                        # - 1~100: ë°±ë¶„ìœ¨ (ì˜ˆ: 29.2)
                        # - 100+: ì´ì  í•©ê³„ (ì˜ˆ: 50.79)
                        if raw_score > 100:
                            # ì´ì ì¸ ê²½ìš°: train ìƒ˜í”Œ ìˆ˜ë¡œ ë‚˜ëˆ”
                            normalized = raw_score / len(train_examples) if len(train_examples) > 0 else 0
                        elif raw_score > 1.0:
                            # ë°±ë¶„ìœ¨ì¸ ê²½ìš° (ì˜ˆ: 29.2 â†’ 0.292)
                            normalized = raw_score / 100.0
                        else:
                            # ì´ë¯¸ ì •ê·œí™”ë¨ (0~1)
                            normalized = raw_score
                        
                        # ë²”ìœ„ ì œí•œ (0~1)
                        normalized = max(0.0, min(1.0, normalized))
                        
                        if normalized > train_score_normalized:
                            train_score_normalized = normalized
                
                # ì •ê·œí™” ì ìˆ˜ â†’ ì›ë³¸ ì ìˆ˜ (0~3.5)
                train_score = train_score_normalized * 3.5  # MAX_SCORE
                print(f"   ğŸ“Š Train Best Score (from COPRO): {train_score_normalized:.3f} ({train_score_normalized*100:.1f}%) â†’ {train_score:.3f}")
            else:
                print(f"   âš ï¸ COPRO results_bestë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # í…ŒìŠ¤íŠ¸ í‰ê°€ (Test ë°ì´í„° ì‚¬ìš©)
            print(f"\nğŸ“Š Depth {step} í…ŒìŠ¤íŠ¸ í‰ê°€...")
            test_results = evaluate_with_dspy(optimized_module, test_examples, None, f"Depth {step} (Test)", num_threads=num_threads)
            
            # Train ì ìˆ˜ ì¶”ê°€
            test_results['train_score'] = train_score
            test_results['train_normalized'] = train_score_normalized
            
            # Trackerì— ìˆ˜ë™ ë¡œê¹… (train ì ìˆ˜ í¬í•¨)
            if tracker:
                tracker.log_step(test_results, f"Depth {step} (Test)")
            
            score = test_results['avg_score']
            
            instruction = _get_instruction(optimized_module)
            num_demos = _get_num_demos(optimized_module)
            
            # Instruction ë³€ê²½ í™•ì¸ ë¡œê¹…
            logger.log_instruction_change(step, instruction)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            improved = state.update(step, score, optimized_module, instruction, num_demos)
            
            logger.log_step(step, score, improved, {
                "num_demos": num_demos,
                "improvement": score - baseline_score,
                "step_time": step_time
            })
            
            # ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ (tracker.log_stepì—ì„œ ì´ë¯¸ ë°ì´í„° ì¶”ê°€ë¨)
            if tracker:
                tracker.plot_metrics()
            
            # Early Stopping ì²´í¬
            if state.should_stop(patience):
                logger.log_early_stop(step, patience, state.best_step)
                break
            
            # ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•´ í˜„ì¬ ëª¨ë“ˆ ì—…ë°ì´íŠ¸
            current_module = optimized_module
        
        # ìµœì¢… ê²°ê³¼
        logger.log_final(state)
        state.save()
        
        # ìµœì¢… instruction ë¹„êµ ì¶œë ¥
        final_instruction = _get_instruction(state.best_module)
        logger.log_final_instruction_comparison(final_instruction)
        
        print("\n" + "="*60)
        print("ğŸ¯ ìµœì í™”ëœ Instruction í™•ì¸")
        print("="*60)
        display_optimized_prompt(state.best_module)
        
        return state.best_module, state
        
    except ImportError as e:
        print(f"âš ï¸ COPROë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        raise
    except Exception as e:
        print(f"âš ï¸ COPRO ì˜¤ë¥˜: {e}")
        raise


def optimize_with_mipro_and_logging(
    module: dspy.Module,
    train_examples: List[dspy.Example],
    test_examples: List[dspy.Example],
    metric_fn: Callable = None,
    num_candidates: int = 10,
    init_temperature: float = 1.4,
    max_bootstrapped_demos: int = 3,
    max_labeled_demos: int = 4,
    num_threads: int = 16,
    patience: int = 3,
    eval_every: int = 2,
    tracker: 'PerformanceTracker' = None
) -> Tuple[dspy.Module, OptimizationState]:
    """
    MIPROv2 ìµœì í™” + ë‹¨ê³„ë³„ ë¡œê¹… + Early Stopping
    
    MIPROv2ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ë² ì´ì§€ì•ˆ ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ë¯€ë¡œ,
    í›„ë³´ë“¤ì„ í‰ê°€í•˜ë©´ì„œ bestë¥¼ ì¶”ì í•©ë‹ˆë‹¤.
    
    Args:
        module: ìµœì í™”í•  DSPy ëª¨ë“ˆ
        train_examples: í•™ìŠµ ë°ì´í„°
        test_examples: í…ŒìŠ¤íŠ¸ ë°ì´í„°
        metric_fn: ë©”íŠ¸ë¦­ í•¨ìˆ˜
        num_candidates: ë² ì´ì§€ì•ˆ ìµœì í™” í›„ë³´ ìˆ˜
        init_temperature: ì´ˆê¸° temperature
        max_bootstrapped_demos: ë¶€íŠ¸ìŠ¤íŠ¸ë© ì˜ˆì‹œ ìˆ˜
        max_labeled_demos: ë¼ë²¨ë§ëœ ì˜ˆì‹œ ìˆ˜
        num_threads: ë³‘ë ¬ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜
        patience: early stopping patience
        eval_every: N í›„ë³´ë§ˆë‹¤ í…ŒìŠ¤íŠ¸ í‰ê°€
    
    Returns:
        (best_module, optimization_state)
    """
    try:
        from dspy.teleprompt import MIPROv2
        
        if metric_fn is None:
            metric_fn = normalized_metric
        
        state = OptimizationState(
            experiment_name="mipro",
            auto_save=True
        )
        logger = OptimizationLogger("mipro")
        
        print("ğŸš€ MIPROv2 ìµœì í™” ì‹œì‘ (Early Stopping í™œì„±í™”)")
        print("   ğŸ“ ìµœì í™” ëŒ€ìƒ: Instruction + Few-shot Demos")
        print(f"   ğŸ”§ ì„¤ì •: candidates={num_candidates}, patience={patience}")
        print("="*60)
        
        # ì›ë³¸ instruction ì €ì¥ ë° ì¶œë ¥
        original_instruction = _get_instruction(module)
        logger.set_original_instruction(original_instruction)
        
        # ì´ˆê¸° í‰ê°€
        print("\nğŸ“Š Depth 0: ë² ì´ìŠ¤ë¼ì¸ í‰ê°€")
        baseline_results = evaluate_with_dspy(module, test_examples, tracker, "Baseline (Test)", num_threads=num_threads)
        baseline_score = baseline_results['avg_score']
        
        instruction = _get_instruction(module)
        state.update(0, baseline_score, module, instruction, 0)
        logger.log_step(0, baseline_score, True, {})
        
        if tracker:
            tracker.plot_metrics()
        
        # MIPROv2 ì‹¤í–‰
        print(f"\n{'ğŸ”„'*20}")
        print("MIPROv2 ìµœì í™” ì‹¤í–‰ ì¤‘...")
        print(f"{'ğŸ”„'*20}")
        
        optimizer = MIPROv2(
            metric=metric_fn,
            auto=None,  # ìˆ˜ë™ ì„¤ì • ëª¨ë“œ (num_candidates/num_trials ì‚¬ìš© ì‹œ í•„ìˆ˜)
            num_candidates=num_candidates,  # ë² ì´ì§€ì•ˆ ìµœì í™” í›„ë³´ ìˆ˜ ì¶”ê°€!
            init_temperature=init_temperature,
            max_bootstrapped_demos=max_bootstrapped_demos,
            max_labeled_demos=max_labeled_demos,
            num_threads=num_threads,
            verbose=True
        )
        
        optimized_module = optimizer.compile(
            module,
            trainset=train_examples,
            num_trials=num_candidates  # ì‹œë„ íšŸìˆ˜ ëª…ì‹œ
        )
        
        # ìµœì¢… í‰ê°€
        print("\nğŸ“Š Depth 1: ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€...")
        final_results = evaluate_with_dspy(optimized_module, test_examples, tracker, "Final (Test)", num_threads=num_threads)
        final_score = final_results['avg_score']
        
        instruction = _get_instruction(optimized_module)
        num_demos = _get_num_demos(optimized_module)
        
        # Instruction ë³€ê²½ í™•ì¸ ë¡œê¹…
        logger.log_instruction_change(1, instruction)
        
        improved = state.update(1, final_score, optimized_module, instruction, num_demos)
        logger.log_step(1, final_score, improved, {
            "num_demos": num_demos,
            "improvement": final_score - baseline_score
        })
        
        if tracker:
            tracker.plot_metrics()
        
        # ìµœì¢… ê²°ê³¼
        logger.log_final(state)
        state.save()
        
        # ìµœì¢… instruction ë¹„êµ ì¶œë ¥
        final_instruction = _get_instruction(state.best_module)
        logger.log_final_instruction_comparison(final_instruction)
        
        print("\n" + "="*60)
        print("ğŸ¯ MIPROv2 ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ í™•ì¸")
        print("="*60)
        display_optimized_prompt(state.best_module)
        
        return state.best_module, state
        
    except ImportError as e:
        print(f"âš ï¸ MIPROv2ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        raise
    except Exception as e:
        print(f"âš ï¸ MIPROv2 ì˜¤ë¥˜: {e}")
        raise


# ============================================
# Helper Functions
# ============================================

def _get_instruction(module: dspy.Module) -> str:
    """ëª¨ë“ˆì—ì„œ instruction ì¶”ì¶œ (DSPy 3.x í˜¸í™˜)"""
    try:
        # 1. predictor ì°¾ê¸° (cot ë˜ëŠ” predict)
        if hasattr(module, 'cot'):
            predictor = module.cot
        elif hasattr(module, 'predict'):
            predictor = module.predict
        else:
            predictor = module
        
        # 2. DSPy 3.x: ChainOfThought.predict.signature.instructions
        #    ChainOfThoughtëŠ” ë‚´ë¶€ì— predict ì†ì„±ì„ ê°€ì§€ê³  ìˆìŒ
        if hasattr(predictor, 'predict') and hasattr(predictor.predict, 'signature'):
            sig = predictor.predict.signature
            if hasattr(sig, 'instructions') and sig.instructions:
                return str(sig.instructions)
        
        # 3. ì§ì ‘ signature ì ‘ê·¼ ì‹œë„
        if hasattr(predictor, 'signature'):
            sig = predictor.signature
            if hasattr(sig, 'instructions') and sig.instructions:
                return str(sig.instructions)
        
        # 4. extended_signature ì‹œë„
        if hasattr(predictor, 'extended_signature'):
            sig = predictor.extended_signature
            if hasattr(sig, 'instructions') and sig.instructions:
                return str(sig.instructions)
        
        # 5. __dict__ì—ì„œ predict ì°¾ê¸° (ChainOfThoughtì˜ ê²½ìš°)
        if hasattr(predictor, '__dict__'):
            for key, val in predictor.__dict__.items():
                if hasattr(val, 'signature'):
                    sig = val.signature
                    if hasattr(sig, 'instructions') and sig.instructions:
                        return str(sig.instructions)
        
        return "(instructionì„ ì°¾ì„ ìˆ˜ ì—†ìŒ)"
    except Exception as e:
        return f"(instruction ì¶”ì¶œ ì˜¤ë¥˜: {e})"


def _get_num_demos(module: dspy.Module) -> int:
    """ëª¨ë“ˆì—ì„œ demo ìˆ˜ ì¶”ì¶œ"""
    try:
        if hasattr(module, 'cot'):
            predictor = module.cot
        elif hasattr(module, 'predict'):
            predictor = module.predict
        else:
            predictor = module
        
        if hasattr(predictor, 'demos') and predictor.demos:
            return len(predictor.demos)
        return 0
    except:
        return 0


# ============================================
# Legacy Functions (ê¸°ì¡´ í˜¸í™˜)
# ============================================

def optimize_with_copro(
    module: dspy.Module,
    train_examples: List[dspy.Example],
    metric_fn: Callable = None,
    breadth: int = 10,
    depth: int = 1,
    init_temperature: float = 0.6,
    num_threads: int = 16
) -> dspy.Module:
    """COPRO ìµœì í™” (ë ˆê±°ì‹œ - ë¡œê¹… ì—†ìŒ)"""
    try:
        from dspy.teleprompt import COPRO
        
        if metric_fn is None:
            metric_fn = normalized_metric
        
        # breadth ìµœì†Œê°’ ê²€ì¦
        if breadth < 2:
            breadth = 2
        
        print("ğŸš€ COPRO ìµœì í™” ì‹œì‘...")
        print(f"   ğŸ”§ ì„¤ì •: breadth={breadth}, depth={depth}")
        
        optimizer = COPRO(
            metric=metric_fn,
            breadth=breadth,
            depth=depth,
            init_temperature=init_temperature,
            verbose=False
        )
        
        optimized_module = optimizer.compile(
            module,
            trainset=train_examples,
            eval_kwargs=dict(num_threads=num_threads, display_progress=True)
        )
        
        display_optimized_prompt(optimized_module)
        print("\nâœ… COPRO ìµœì í™” ì™„ë£Œ!")
        return optimized_module
        
    except Exception as e:
        print(f"âš ï¸ COPRO ì˜¤ë¥˜: {e}")
        raise


def optimize_with_mipro(
    module: dspy.Module,
    train_examples: List[dspy.Example],
    metric_fn: Callable = None,
    num_candidates: int = 10,
    init_temperature: float = 1.4,
    max_bootstrapped_demos: int = 3,
    max_labeled_demos: int = 4,
    num_threads: int = 16
) -> dspy.Module:
    """MIPROv2 ìµœì í™” (ë ˆê±°ì‹œ - ë¡œê¹… ì—†ìŒ)"""
    try:
        from dspy.teleprompt import MIPROv2
        
        if metric_fn is None:
            metric_fn = normalized_metric
        
        print("ğŸš€ MIPROv2 ìµœì í™” ì‹œì‘...")
        print(f"   ğŸ”§ ì„¤ì •: candidates={num_candidates}")
        
        optimizer = MIPROv2(
            metric=metric_fn,
            auto=None,  # ìˆ˜ë™ ì„¤ì • ëª¨ë“œ (num_candidates/num_trials ì‚¬ìš© ì‹œ í•„ìˆ˜)
            num_candidates=num_candidates,
            init_temperature=init_temperature,
            max_bootstrapped_demos=max_bootstrapped_demos,
            max_labeled_demos=max_labeled_demos,
            num_threads=num_threads,
            verbose=True
        )
        
        optimized_module = optimizer.compile(
            module,
            trainset=train_examples,
            num_trials=num_candidates  # auto=Noneì¼ ë•Œ num_trials í•„ìˆ˜
        )
        
        display_optimized_prompt(optimized_module)
        print("\nâœ… MIPROv2 ìµœì í™” ì™„ë£Œ!")
        return optimized_module
        
    except Exception as e:
        print(f"âš ï¸ MIPROv2 ì˜¤ë¥˜: {e}")
        raise


def display_optimized_prompt(module: dspy.Module):
    """ìµœì í™”ëœ ëª¨ë“ˆì˜ í”„ë¡¬í”„íŠ¸ ì¶œë ¥"""
    try:
        if hasattr(module, 'cot'):
            predictor = module.cot
        elif hasattr(module, 'predict'):
            predictor = module.predict
        else:
            predictor = module
        
        if hasattr(predictor, 'extended_signature'):
            sig = predictor.extended_signature
            if hasattr(sig, 'instructions'):
                print(f"\nğŸ“‹ ìµœì í™”ëœ Instruction:")
                print("-" * 50)
                print(sig.instructions)
                print("-" * 50)
        
        if hasattr(predictor, 'signature'):
            sig = predictor.signature
            if hasattr(sig, 'instructions'):
                print(f"\nğŸ“‹ Signature Instruction:")
                print("-" * 50)
                print(sig.instructions)
                print("-" * 50)
        
        if hasattr(predictor, 'demos') and predictor.demos:
            print(f"\nğŸ“š Few-shot Demos ({len(predictor.demos)}ê°œ):")
            for i, demo in enumerate(predictor.demos[:3]):
                print(f"\n  [Demo {i+1}]")
                if hasattr(demo, 'question'):
                    print(f"  Q: {str(demo.question)[:100]}...")
                if hasattr(demo, 'sql_query'):
                    print(f"  SQL: {str(demo.sql_query)[:100]}...")
        else:
            print("\nğŸ“š Few-shot Demos: ì—†ìŒ (Zero-shot)")
        
    except Exception as e:
        print(f"í”„ë¡¬í”„íŠ¸ ì¶œë ¥ ì˜¤ë¥˜: {e}")


def compare_prompts(baseline_module: dspy.Module, optimized_module: dspy.Module):
    """ë² ì´ìŠ¤ë¼ì¸ê³¼ ìµœì í™”ëœ ëª¨ë“ˆì˜ í”„ë¡¬í”„íŠ¸ ë¹„êµ"""
    print("\n" + "="*60)
    print("ğŸ“Š í”„ë¡¬í”„íŠ¸ ë¹„êµ: Baseline vs Optimized")
    print("="*60)
    
    print("\nğŸ”µ [Baseline]")
    display_optimized_prompt(baseline_module)
    
    print("\nğŸŸ¢ [Optimized]")
    display_optimized_prompt(optimized_module)


# ============================================
# Main Pipeline (Updated)
# ============================================

def run_optimization_pipeline(
    module: dspy.Module,
    train_examples: List[dspy.Example],
    test_examples: List[dspy.Example] = None,
    tracker: PerformanceTracker = None,
    optimizer_type: str = "mipro",
    config: Optional[OptimizerConfig] = None,
    save_intermediate: bool = True,
    use_early_stopping: bool = True,
    patience: int = 5
) -> Tuple[dspy.Module, dict]:
    """
    ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë¡œê¹… + Early Stopping ì§€ì›)
    
    Args:
        module: ìµœì í™”í•  ëª¨ë“ˆ
        train_examples: í•™ìŠµ ë°ì´í„° (COPRO/MIPROv2 ìµœì í™”ìš©)
        test_examples: í…ŒìŠ¤íŠ¸ ë°ì´í„° (ë‹¨ê³„ë³„ í‰ê°€ + ìµœì¢… í‰ê°€ìš©)
        tracker: PerformanceTracker
        optimizer_type: "copro" ë˜ëŠ” "mipro"
        config: OptimizerConfig (ì„ íƒì‚¬í•­)
        save_intermediate: ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì—¬ë¶€
        use_early_stopping: Early Stopping ì‚¬ìš© ì—¬ë¶€
        patience: Early Stopping patience
    
    Returns:
        (optimized_module, final_results)
    
    ë°ì´í„° ì‚¬ìš©:
        - train_examples: COPRO/MIPROv2 í”„ë¡¬í”„íŠ¸ ìµœì í™”
        - test_examples: ë‹¨ê³„ë³„ í‰ê°€ + ìµœì¢… ì„±ëŠ¥ í‰ê°€
    """
    if config is None:
        config = OptimizerConfig(optimizer_type=optimizer_type)
    
    baseline_module = module
    tracker.start()
    
    print("\n" + "ğŸŸ¡"*25)
    print(f"ìµœì í™” ì‹¤í–‰ ({optimizer_type.upper()})")
    if use_early_stopping:
        print(f"   Early Stopping: patience={patience} (Test ê¸°ë°˜)")
    print("ğŸŸ¡"*25)
    
    optimization_start = time.time()
    
    if use_early_stopping:
        # Early Stopping ë²„ì „ ì‚¬ìš© (test_examplesë¡œ í‰ê°€)
        if optimizer_type == "copro":
            kwargs = config.to_copro_kwargs()
            optimized_module, opt_state = optimize_with_copro_and_logging(
                module=module,
                train_examples=train_examples,
                test_examples=test_examples,  # Test ì‚¬ìš©!
                metric_fn=normalized_metric,
                patience=patience,
                tracker=tracker,  # PerformanceTracker ì „ë‹¬!
                **kwargs
            )
        elif optimizer_type == "mipro":
            kwargs = config.to_mipro_kwargs()
            optimized_module, opt_state = optimize_with_mipro_and_logging(
                module=module,
                train_examples=train_examples,
                test_examples=test_examples,  # Test ì‚¬ìš©!
                metric_fn=normalized_metric,
                patience=patience,
                tracker=tracker,  # PerformanceTracker ì „ë‹¬!
                **kwargs
            )
        else:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” optimizer_type: {optimizer_type}")
    else:
        # ê¸°ì¡´ ë²„ì „ ì‚¬ìš©
        if optimizer_type == "copro":
            kwargs = config.to_copro_kwargs()
            optimized_module = optimize_with_copro(
                module=module,
                train_examples=train_examples,
                metric_fn=normalized_metric,
                **kwargs
            )
        elif optimizer_type == "mipro":
            kwargs = config.to_mipro_kwargs()
            optimized_module = optimize_with_mipro(
                module=module,
                train_examples=train_examples,
                metric_fn=normalized_metric,
                **kwargs
            )
        else:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” optimizer_type: {optimizer_type}")
    
    optimization_time = time.time() - optimization_start
    print(f"\nâ±ï¸  ìµœì í™” ì‹œê°„: {optimization_time:.1f}ì´ˆ")
    
    # ìµœì¢… í‰ê°€ (Test ë°ì´í„° - Unseen)
    print("\n" + "ğŸŸ¢"*25)
    print("ìµœì¢… í‰ê°€ (Test - Unseen Data)")
    print("ğŸŸ¢"*25)
    optimized_results = evaluate_with_dspy(
        optimized_module, test_examples, tracker, "Final (Test)"
    )
    
    # í”„ë¡¬í”„íŠ¸ ë¹„êµ
    print("\n" + "ğŸ”®"*25)
    print("í”„ë¡¬í”„íŠ¸ ë³€í™” í™•ì¸")
    print("ğŸ”®"*25)
    compare_prompts(baseline_module, optimized_module)
    
    # ìµœì¢… ê·¸ë˜í”„ ì €ì¥
    tracker.plot_metrics()
    tracker.save_history()
    tracker.summary()
    
    return optimized_module, optimized_results


# ë ˆê±°ì‹œ í˜¸í™˜ í•¨ìˆ˜
def run_optimization_with_tracking(
    module: dspy.Module,
    train_examples: List[dspy.Example],
    test_examples: List[dspy.Example],
    tracker: PerformanceTracker,
    optimizer_type: str = "mipro",
    save_intermediate: bool = True,
    breadth: int = 10,
    depth: int = 3,
    init_temperature: float = 0.6,
    num_threads: int = 10,
) -> Tuple[dspy.Module, dict]:
    """ë ˆê±°ì‹œ í˜¸í™˜ í•¨ìˆ˜"""
    config = OptimizerConfig(
        optimizer_type=optimizer_type,
        breadth=breadth,
        depth=depth,
        init_temperature=init_temperature,
        num_threads=num_threads
    )
    
    return run_optimization_pipeline(
        module=module,
        train_examples=train_examples,
        test_examples=test_examples,
        tracker=tracker,
        optimizer_type=optimizer_type,
        config=config,
        save_intermediate=save_intermediate,
        use_early_stopping=True,
        patience=2
    )


print("âœ… ìµœì í™” í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ")
print("=" * 50)
print("ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì í™” ë°©ë²•:")
print("   1ï¸âƒ£ optimize_with_copro_and_logging()  - COPRO + ë¡œê¹… + Early Stopping â­")
print("   2ï¸âƒ£ optimize_with_mipro_and_logging()  - MIPROv2 + ë¡œê¹… + Early Stopping â­")
print("   3ï¸âƒ£ optimize_with_copro()  - COPRO (ë ˆê±°ì‹œ)")
print("   4ï¸âƒ£ optimize_with_mipro()  - MIPROv2 (ë ˆê±°ì‹œ)")
print("=" * 50)
