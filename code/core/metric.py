"""
Metric Functions for Text-to-SQL Evaluation
============================================
SQL ì¿¼ë¦¬ í‰ê°€ë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ í•¨ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.

ë³´ìƒ ì²´ê³„:
- Queryì™€ DB ì¡°íšŒ ê²°ê³¼ê°€ ì™„ë²½íˆ ì¼ì¹˜: 3.5ì 
- QueryëŠ” ë‹¤ë¥´ì§€ë§Œ DB ê²°ê³¼ê°€ ë™ì¼: 3.0ì 
- Evidence ìœ ì‚¬ë„ ê¸°ë°˜: 0.5 ~ 2.5ì 
- ì‹¤í–‰ì€ ë˜ì§€ë§Œ ê²°ê³¼ê°€ í‹€ë¦¼: 0.5ì 
- ì—ëŸ¬ ë°œìƒ: 0.0ì 
"""

import logging
import traceback
from typing import Any, Optional
from .utiles import execute_sql, compare_sql, compare_results, calculate_evidence_similarity

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ì—ëŸ¬ ë¡œê¹… í™œì„±í™” í”Œë˜ê·¸
VERBOSE_ERRORS = True  # Trueë©´ ì—ëŸ¬ ì‹œ ìƒì„¸ ì¶œë ¥

# ì ìˆ˜ ìƒìˆ˜
MAX_SCORE = 3.5
PERFECT_MATCH_SCORE = 3.5
RESULT_MATCH_SCORE = 3.0
MIN_PARTIAL_SCORE = 0.5
MAX_PARTIAL_SCORE = 2.5
WRONG_RESULT_SCORE = 0.5
ERROR_SCORE = 0.0


def text_to_sql_metric(example: Any, prediction: Any, trace: Any = None) -> float:
    """
    Text-to-SQL ë©”íŠ¸ë¦­ í•¨ìˆ˜ (ì›ë³¸ ì ìˆ˜: 0 ~ 3.5)
    
    ë³´ìƒ ì²´ê³„:
    - Query + ê²°ê³¼ ì™„ë²½ ì¼ì¹˜: 3.5ì 
    - Query ë‹¤ë¥´ì§€ë§Œ ê²°ê³¼ ë™ì¼: 3.0ì 
    - Evidence ìœ ì‚¬ë„ ê¸°ë°˜: 0.5 ~ 2.5ì 
    - ì‹¤í–‰ë˜ì§€ë§Œ ê²°ê³¼ í‹€ë¦¼: 0.5ì 
    - ì—ëŸ¬ ë°œìƒ: 0.0ì 
    
    Args:
        example: DSPy Example (gold_sql, gold_evidence í¬í•¨)
        prediction: DSPy Prediction (sql_query, evidence í¬í•¨)
        trace: DSPy trace (ì‚¬ìš© ì•ˆ í•¨)
    
    Returns:
        ì ìˆ˜ (0.0 ~ 3.5)
    """
    question = getattr(example, 'question', '')[:50]  # ë””ë²„ê¹…ìš©
    
    try:
        # predictionì´ Noneì¸ ê²½ìš° ì²˜ë¦¬
        if prediction is None:
            if VERBOSE_ERRORS:
                print(f"âŒ [METRIC] predictionì´ Noneì…ë‹ˆë‹¤. Q: {question}...")
            return ERROR_SCORE
        
        gold_sql = getattr(example, 'gold_sql', '')
        gold_evidence = getattr(example, 'gold_evidence', '')
        pred_sql = getattr(prediction, 'sql_query', '')
        pred_evidence = getattr(prediction, 'evidence', '')
        
        # pred_sqlì´ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš°
        if not pred_sql:
            if VERBOSE_ERRORS:
                print(f"âŒ [METRIC] pred_sqlì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. Q: {question}...")
            return ERROR_SCORE
        
        # 1. ì˜ˆì¸¡ëœ SQL ì‹¤í–‰
        pred_success, pred_result = execute_sql(pred_sql)
        
        # ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸ ë¡œê¹…
        if not pred_success:
            if VERBOSE_ERRORS:
                error_msg = str(pred_result)[:100]
                # DB ì—°ê²° ì—ëŸ¬ëŠ” í¬ë¦¬í‹°ì»¬ - ë°˜ë“œì‹œ ì¶œë ¥
                if "unable to open database" in error_msg.lower() or "no such table" in error_msg.lower():
                    print(f"ğŸš¨ [CRITICAL] DB ì—°ê²°/í…Œì´ë¸” ì—ëŸ¬! {error_msg}")
                else:
                    print(f"âš ï¸ [METRIC] pred_sql ì‹¤í–‰ ì‹¤íŒ¨: {error_msg}")
            return ERROR_SCORE
        
        # 2. Gold SQL ì‹¤í–‰
        gold_success, gold_result = execute_sql(gold_sql)
        if not gold_success:
            if VERBOSE_ERRORS:
                error_msg = str(gold_result)[:100]
                if "unable to open database" in error_msg.lower():
                    print(f"ğŸš¨ [CRITICAL] Gold SQL DB ì—°ê²° ì—ëŸ¬! {error_msg}")
            return WRONG_RESULT_SCORE  # Gold SQL ì—ëŸ¬ì§€ë§Œ ì˜ˆì¸¡ì€ ì‹¤í–‰ë¨
        
        # 3. SQL ë° ê²°ê³¼ ë¹„êµ
        sql_match = compare_sql(pred_sql, gold_sql)
        result_match = compare_results(pred_result, gold_result)
        
        # 4. ë³´ìƒ ê³„ì‚°
        if sql_match and result_match:
            return PERFECT_MATCH_SCORE
        elif result_match:
            return RESULT_MATCH_SCORE
        else:
            # ê²°ê³¼ê°€ ë‹¤ë¦„ - evidence ìœ ì‚¬ë„ë¡œ ë¶€ë¶„ ì ìˆ˜
            evidence_sim = calculate_evidence_similarity(pred_evidence, gold_evidence)
            if evidence_sim > 0.1:
                # evidence_sim (0~1) â†’ 0.5 ~ 2.5ë¡œ ìŠ¤ì¼€ì¼ë§
                return MIN_PARTIAL_SCORE + evidence_sim * 2.0
            else:
                return WRONG_RESULT_SCORE
                
    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒ ì‹œ ìƒì„¸ ë¡œê¹…
        if VERBOSE_ERRORS:
            print(f"ğŸš¨ [METRIC ERROR] ì˜ˆì™¸ ë°œìƒ: {type(e).__name__}: {str(e)[:100]}")
            if "database" in str(e).lower() or "sqlite" in str(e).lower():
                print(f"   âš ï¸ DB ê´€ë ¨ ì—ëŸ¬ì…ë‹ˆë‹¤. DB ê²½ë¡œ/ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
                traceback.print_exc()
        return ERROR_SCORE


def normalized_metric(example: Any, prediction: Any, trace: Any = None) -> float:
    """
    ì •ê·œí™”ëœ ë©”íŠ¸ë¦­ (0~1 ë²”ìœ„) - DSPy ìµœì í™”ìš©
    
    DSPyì˜ COPRO/MIPROv2/EvaluateëŠ” 0~1 ë²”ìœ„ì˜ ë©”íŠ¸ë¦­ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤.
    ì›ë³¸ ì ìˆ˜(0~3.5)ë¥¼ 0~1ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.
    
    Args:
        example: DSPy Example
        prediction: DSPy Prediction
        trace: DSPy trace
    
    Returns:
        ì •ê·œí™”ëœ ì ìˆ˜ (0.0 ~ 1.0)
    """
    try:
        score = text_to_sql_metric(example, prediction, trace)
        return score / MAX_SCORE
    except Exception as e:
        if VERBOSE_ERRORS:
            print(f"ğŸš¨ [NORMALIZED_METRIC ERROR] {type(e).__name__}: {str(e)[:100]}")
        return 0.0


def binary_metric(example: Any, prediction: Any, trace: Any = None) -> float:
    """
    ì´ì§„ ë©”íŠ¸ë¦­ (0 ë˜ëŠ” 1) - ê²°ê³¼ ì¼ì¹˜ ì—¬ë¶€ë§Œ íŒë‹¨
    
    Args:
        example: DSPy Example
        prediction: DSPy Prediction
        trace: DSPy trace
    
    Returns:
        1.0 (ê²°ê³¼ ì¼ì¹˜) ë˜ëŠ” 0.0 (ë¶ˆì¼ì¹˜)
    """
    score = text_to_sql_metric(example, prediction, trace)
    return 1.0 if score >= RESULT_MATCH_SCORE else 0.0


def execution_metric(example: Any, prediction: Any, trace: Any = None) -> float:
    """
    ì‹¤í–‰ ì„±ê³µ ë©”íŠ¸ë¦­ - SQLì´ ì—ëŸ¬ ì—†ì´ ì‹¤í–‰ë˜ëŠ”ì§€ë§Œ íŒë‹¨
    
    Args:
        example: DSPy Example
        prediction: DSPy Prediction
        trace: DSPy trace
    
    Returns:
        1.0 (ì‹¤í–‰ ì„±ê³µ) ë˜ëŠ” 0.0 (ì‹¤í–‰ ì‹¤íŒ¨)
    """
    pred_sql = getattr(prediction, 'sql_query', '')
    success, _ = execute_sql(pred_sql)
    return 1.0 if success else 0.0


class MetricConfig:
    """ë©”íŠ¸ë¦­ ì„¤ì • í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        perfect_match_score: float = 3.5,
        result_match_score: float = 3.0,
        min_partial_score: float = 0.5,
        max_partial_score: float = 2.5,
        wrong_result_score: float = 0.5,
        error_score: float = 0.0
    ):
        self.perfect_match = perfect_match_score
        self.result_match = result_match_score
        self.min_partial = min_partial_score
        self.max_partial = max_partial_score
        self.wrong_result = wrong_result_score
        self.error = error_score
        self.max_score = perfect_match_score


def create_custom_metric(config: MetricConfig):
    """ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ í•¨ìˆ˜ ìƒì„±"""
    def custom_metric(example: Any, prediction: Any, trace: Any = None) -> float:
        gold_sql = getattr(example, 'gold_sql', '')
        gold_evidence = getattr(example, 'gold_evidence', '')
        pred_sql = getattr(prediction, 'sql_query', '')
        pred_evidence = getattr(prediction, 'evidence', '')
        
        pred_success, pred_result = execute_sql(pred_sql)
        if not pred_success:
            return config.error
        
        gold_success, gold_result = execute_sql(gold_sql)
        if not gold_success:
            return config.wrong_result
        
        sql_match = compare_sql(pred_sql, gold_sql)
        result_match = compare_results(pred_result, gold_result)
        
        if sql_match and result_match:
            return config.perfect_match
        elif result_match:
            return config.result_match
        else:
            evidence_sim = calculate_evidence_similarity(pred_evidence, gold_evidence)
            if evidence_sim > 0.1:
                return config.min_partial + evidence_sim * (config.max_partial - config.min_partial)
            else:
                return config.wrong_result
    
    return custom_metric


# ë©”íŠ¸ë¦­ ë ˆì§€ìŠ¤íŠ¸ë¦¬
METRIC_REGISTRY = {
    "default": text_to_sql_metric,
    "normalized": normalized_metric,
    "binary": binary_metric,
    "execution": execution_metric,
}


def get_metric(name: str = "normalized"):
    """ì´ë¦„ìœ¼ë¡œ ë©”íŠ¸ë¦­ í•¨ìˆ˜ ë°˜í™˜"""
    if name not in METRIC_REGISTRY:
        raise ValueError(f"Unknown metric: {name}. Available: {list(METRIC_REGISTRY.keys())}")
    return METRIC_REGISTRY[name]


def register_metric(name: str, metric_fn):
    """ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ì„ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡"""
    METRIC_REGISTRY[name] = metric_fn
    print(f"âœ… Metric '{name}' ë“±ë¡ ì™„ë£Œ")


print("âœ… ë©”íŠ¸ë¦­ í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ")
